---
title: "Laboratorio 4 Estadística general"
author: 'Katherine Benjumea Ortiz, Brigith Lorena Giraldo Vargas, Valentina Ochoa
  Arboleda, Tomás Atehortua Ceferino, Danilo de Jesús Toro Echeverri'
date: "2023-03-05"
output:
  html_document: default
  pdf_document: default
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
 
## Bloque 1

### 1
```{r}

library(readr)
ventypub = read_csv("C:/Users/K0012/OneDrive/Escritorio/universidad/Estadística/ventaypub.csv")
```

### 2
```{r}

ventas = ventypub$Ventas
publicidad = ventypub$Publicidad

#diagrma dispersión ventas vs publicidad
plot(ventas, publicidad)
modelo = lm(publicidad ~ ventas, data = ventypub)
abline(modelo, col = "red")

```
De acuerdo a los datos reflejados en el diagrama de dispersión se puede observar que la
relación de las dos variables es debil, ya que los datos son muy dispersos y no se
observa algún patrón.


### 3
```{r}

length(ventas)
length(publicidad)

b1=sum((publicidad-mean(publicidad))*(ventas-mean(ventas)))/sum((publicidad-mean(publicidad))^2)

b0=mean(ventas)-b1*mean(publicidad)

correlacion1 = cor(ventas,publicidad)

#falta cual es la venta variable

print(paste("Pendiente:", b1))
print(paste("Intercepto:",b0))
print(paste("La correlación entre la variable venta y publicidad es:",correlacion1))


prom = mean(publicidad)

venta_variable <- b1 * prom

print(paste("la venta adicional es:",venta_variable))
```
#correlación positiva y débil

### 4
#regresión lineal con lm
```{r}

Ing = lm(ventas ~ publicidad)

β0 = coef(Ing)[1] 
β1 = coef(Ing)[2] 

print(paste("β0:", β0))
print(paste("β1:",β1))

```
Luego de realizar la regresión lineal usando el método de minimos cuadrados y
la función lm de R, se logra observar que no hay discrepancia en los datos, ya
que con ambos procedimientos se obtuvo el mismo resultado

### 5
```{r}

resumen <- summary(Ing)

coe_determinacion <- resumen$r.squared # Coeficiente de determinación (R cuadrado)

coe_ajustado <- resumen$adj.r.squared # Coeficiente de determinación ajustado

print(paste("R cuadrado:", coe_determinacion))
print(paste("R cuadrado ajustado:",coe_ajustado))


```
El coeficiente de determinación es 0.12129, lo que significa que aproximadamente
el 12,13% es la relación encontrada entre la influencia de la publicidad en las
ventas y el coeficiente de determinación ajustado sugiere que no se han obtenido
mejoras significativas con los gastos de publicidad, ya que este es menor que el
de determinacion.


### 6 
```{r}

correlacion2 = cor(ventas,publicidad)
print(paste("Coeficiente de correlación es:", correlacion2))

```
Este coeficiente no es suficiente para determinar si el ajuste del modelo lineal
es sólido, ya que para esto es necesario tener en cuenta otros parametros como 
por ejemplo el tamño de la muestra, significancia estadística, entre otros.
La información que nos proporciona este coeficiente es que el modelo presenta
una correlación positiva y débil en las variables de publicidad y ventas.

### 7
```{r}

costo_dado <- 22 

nuevo_datos <- data.frame(ventas = costo_dado) 

venta <- predict(Ing, newdata = data.frame(publicidad = costo_dado))

print(paste("Ingreso por ventas (en millones de pesos):", venta))

```


## Bloque 2

```{r}
x = data$Publicidad
y = data$Ventas
mod = lm(y ~ x, data)
modsum = summary(mod)
modsum
```

### 1
¿Es el modelo lineal el mas adecuado para hacer una analisis de regresion en
este caso? Realice una estimacion puntual de la desviacion estandar.
```{r}
plot(x,y)
```


```{r}
r = cor(x,y)
r^2
```

### 2
Realice un breve estudio de los residuos que permita validar los supuestos de 
la regresion. Analizar linealidad y homocedasticidad. Incluya grafico de
normalidad de los residuos estandarizados, contraste de hipotesis sobre
normalidad e intervalo de confianza del 95 % .
```{r}
plot(mod)
```

En el contexto de la linealidad, se observa una relación relativamente débil entre las variables, ya que los datos no siguen
completamente una línea recta. Además, se identifican algunos valores atípicos notables, como los puntos 9, 30 y 40, que parecen
desviarse significativamente de la tendencia general.

Es importante tener en cuenta que estos valores atípicos pueden tener un impacto en el ajuste y la interpretación del modelo de
regresión lineal. Estos puntos pueden ejercer una influencia desproporcionada en los resultados y afectar la precisión de las
estimaciones de los coeficientes y los intervalos de confianza.

Por otro lado, haciando el análisis si los datos cumplen o no homocedasticidad, se concluye que no se encuentra homocedasticidad en
los datos, más bien heterocedasticidad. Ya que, la variabilidad de los errores no es constante y cambia a lo largo de los valores de
las variables independientes. La dispersión de los residuos aumentan a medida que los valores de ventas cambian, lo que indica que
la varianza de los errores no es constante.

### 3 
Determine si el modelo es estadisticamente significativo

R/ El modelo es estadisticamente significativo si se rechaza la hipotesis
nula.
```{r}
fsta = modsum$fstatistic
pValue = pf(fsta["value"], fsta["numdf"], fsta["dendf"], lower.tail = FALSE)
pValue
```
"F-statistic" muestra el valor del estadístico F y sus grados de libertad
asociados. En este caso, el valor del estadístico F es 5.384 y tiene 1 y 39
grados de libertad. "F-statistic" también muestra el valor p asociado al estadístico F (p-value), que en este caso es 0.02565

Como el valor p es 0.02565, que es menor que 0.05. Se puede
concluir que el modelo en su conjunto es estadísticamente significativo a un
nivel de significancia del 0.05.


### 4
Calcular la matriz de varianzas y covarianzas
```{r}
matvc = vcov(mod)
matvc
```

### 5
Calcular el error estandar de cada coeficiente.
```{r}
b0andb1var = diag(matvc)
sqrt(b0andb1var)
```


### 6
Determinar si β0 y β1 son estadisticamente significativos en el modelo

```{r}
modsum$coefficients
```
Para el intercepto (β0), el valor p es 6.55e-07, que es mucho más pequeño que
0.05. Para la pendiente (β1), el valor p es 0.0256, también menor que 0.05.
Por lo tanto, en ambos casos, se puede concluir que los coeficientes son
estadísticamente significativos, ya que las hipótesis nulas correspondientes se
rechazan a un nivel de significancia del 0.05.

### 7
Calcule intervalos de confianza del 95 % y 99 % para los parametros β0 y β1.
```{r}
confint(mod, level = 0.99)
```
La columna 0.5% representa el límite inferior del intervalo de confianza al 0.5%, y la columna 99.5% representa el límite
superior del intervalo de confianza al 99.5%.

La fila Intercept indica el valor estimado de la variable dependiente cuando la variable independiente es igual a cero. El
intervalo de confianza al 99% para el coeficiente de la intersección del modelo es [3.2944537, 8.8377682], lo que significa que se
estima con un 99% de confianza.

La fila ventas indica cómo cambia en promedio la variable dependiente cuando la variable independiente aumenta en una unidad. El
intervalo de confianza al 99% para el coeficiente de ventas, la variable independiente, es [-0.0337083, 0.4372138]. Esto indica que
se estima con un 99% de confianza que el valor verdadero del coeficiente de ventas se encuentra dentro de este intervalo.
```{r}
confint(mod, level = 0.95)
```
El intervalo de confianza del 95% para el coeficiente de la intersección (Intercept) del modelo es [3.99580602, 8.1364159], lo que
significa que se estima con un 95% de confianza que el valor verdadero del coeficiente se encuentra dentro de este intervalo.

El intervalo de confianza del 95% para el coeficiente de ventas, la variable independiente, es [0.02587379, 0.3776317]. Esto indica
que se estima con un 95% de confianza que el valor verdadero del coeficiente de ventas se encuentra dentro de este intervalo.

